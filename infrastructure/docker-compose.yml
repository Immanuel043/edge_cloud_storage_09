version: '3.8'

services:
  # PostgreSQL Database
  postgres:
    image: postgres:15-alpine
    container_name: edge-postgres
    environment:
      POSTGRES_DB: edge_cloud
      POSTGRES_USER: edge_admin
      POSTGRES_PASSWORD: secure_password
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
      - ../scripts/init-db.sql:/docker-entrypoint-initdb.d/init.sql
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U edge_admin -d edge_cloud"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Redis Cache & Session Store
  redis:
    image: redis:7-alpine
    container_name: edge-redis
    command: redis-server --appendonly yes --maxmemory 2gb --maxmemory-policy allkeys-lru
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 2.5G
        reservations:
          memory: 512M

  # Elasticsearch for Search & Analytics
  elasticsearch:
    image: elasticsearch:8.11.0
    container_name: edge-elasticsearch
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
      - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data
    healthcheck:
      test: ["CMD-SHELL", "curl -s http://localhost:9200/_cluster/health | grep -q '\"status\":\"[green|yellow]\"'"]
      interval: 30s
      timeout: 10s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # ClickHouse for Analytics
  clickhouse:
    image: clickhouse/clickhouse-server:23.10
    container_name: edge-clickhouse
    ports:
      - "8123:8123"
      - "9000:9000"
    volumes:
      - clickhouse_data:/var/lib/clickhouse
    healthcheck:
      test: ["CMD", "clickhouse-client", "--query", "SELECT 1"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  # Zookeeper for Kafka
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: edge-zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - zookeeper_data:/var/lib/zookeeper/data
      - zookeeper_logs:/var/lib/zookeeper/log
    healthcheck:
      test: ["CMD", "nc", "-z", "localhost", "2181"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Kafka Message Broker
  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: edge-kafka
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: "true"
      KAFKA_LOG4J_LOGGERS: "kafka.controller=INFO,kafka.producer.async.DefaultEventHandler=INFO,state.change.logger=INFO"
      KAFKAJS_NO_PARTITIONER_WARNING: 1
    volumes:
      - kafka_data:/var/lib/kafka/data
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Storage Service (FastAPI) - THE MAIN FIX
  storage-service:
    build:
      context: ../services/storage-service
      dockerfile: Dockerfile
    container_name: edge-storage-service
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
    environment:
      DB_HOST: postgres
      DATABASE_URL: postgresql+asyncpg://edge_admin:secure_password@postgres:5432/edge_cloud
      REDIS_URL: redis://redis:6379
      ELASTICSEARCH_URL: http://elasticsearch:9200
      KAFKA_BROKERS: kafka:9092
      STORAGE_ROOT: /app/storage
      SECRET_KEY: ${SECRET_KEY:-your-secret-key-here}
      # CRITICAL: Reduce chunk size for memory management
      CHUNK_SIZE: 33554432          # 32MB chunks instead of 64MB
      MAX_FILE_SIZE: 21474836480    # 20GB
      COMPRESSION_LEVEL: 3
      BACKUP_ENABLED: "false"
      USE_X_ACCEL: "1"
      # Add memory management settings
      PYTHONMALLOC: malloc
      MALLOC_TRIM_THRESHOLD: 131072   # fixed env var name (no trailing underscore)
      
    ports:
      - "8001:8000"
    volumes:
     - storage_data:/app/storage
      # Add temp directory with size limit
     - /tmp/upload_temp:/tmp/upload_temp
    # Local docker-compose resource limits (works with many compose setups)
    mem_limit: 3g
    cpus: "2.0"
    # CRITICAL: Add resource limits for Swarm (only used when using `docker stack deploy`)
    deploy:
      resources:
        limits:
          memory: 3G              # Allow up to 3GB
          cpus: '2.0'             # Limit CPU usage
        reservations:
          memory: 1G              # Reserve 1GB
          cpus: '0.5'
    # (removed invalid top-level memswap_limit â€” configure swap at daemon or use docker run flags)
    # Better, simpler healthcheck (curl is more reliable & lighter weight)
    healthcheck:
      test: ["CMD-SHELL", "curl -f http://localhost:8000/api/v1/health || exit 1"]
      interval: 20s
      timeout: 10s
      retries: 10
      start_period: 60s
    restart: unless-stopped
    # Add ulimits for file handling
    ulimits:
      nofile:
        soft: 65536
        hard: 65536

  # Web Service (Node.js)
  web-service:
    build:
      context: ../services/web-service
      dockerfile: Dockerfile
    container_name: edge-web-service
    depends_on:
      postgres:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
      storage-service:
        condition: service_healthy
    environment:
      NODE_ENV: ${NODE_ENV:-development}
      PORT: 3001
      DATABASE_URL: postgresql://edge_admin:secure_password@postgres:5432/edge_cloud
      REDIS_URL: redis://redis:6379
      KAFKA_BROKERS: kafka:9092
      STORAGE_SERVICE_URL: http://storage-service:8000
      SESSION_SECRET: ${SESSION_SECRET:-your-session-secret-here}
      FRONTEND_URL: ${FRONTEND_URL:-http://localhost:3000}
      KAFKAJS_NO_PARTITIONER_WARNING: 1
    ports:
      - "3001:3001"
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 256M

  chunk-processor:
    build:
      context: ../services/storage-service
      dockerfile: Dockerfile
    command: python -m app.workers.chunk_processor
    deploy:
      replicas: 2              # Reduce replicas to save memory
      resources:
        limits:
          memory: 1G           # Limit each processor
        reservations:
          memory: 256M
    environment:
      DATABASE_URL: postgresql+asyncpg://edge_admin:secure_password@postgres:5432/edge_cloud
      REDIS_URL: redis://redis:6379
      KAFKA_BROKERS: kafka:9092
      CHUNK_SIZE: 33554432     # Same 32MB chunk size
    depends_on:
      kafka:
        condition: service_healthy
      redis:
        condition: service_healthy
      postgres:
        condition: service_healthy
    volumes:
      - /tmp/chunks:/tmp/chunks

  # Nginx reverse-proxy
  nginx:
    image: nginx:stable
    container_name: edge-nginx
    depends_on:
      storage-service:
        condition: service_healthy
      web-service:
        condition: service_healthy
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - storage_data:/app/storage:ro
      # Create temp directory for uploads
      - /tmp/nginx_uploads:/tmp/nginx_uploads
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 128M
    networks:
      - default

# Named volumes for data persistence
volumes:
  postgres_data:
    driver: local
  redis_data:
    driver: local
  elasticsearch_data:
    driver: local
  clickhouse_data:
    driver: local
  zookeeper_data:
    driver: local
  zookeeper_logs:
    driver: local
  kafka_data:
    driver: local
  storage_data:
    driver: local

# Networks
networks:
  default:
    name: edge-cloud-network
    driver: bridge